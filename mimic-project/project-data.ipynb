{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b945709a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DuckDB attached to remote PostgreSQL successfully.\n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "con = duckdb.connect()\n",
    "\n",
    "try:\n",
    "    con.sql(f\"\"\"\n",
    "        INSTALL postgres;\n",
    "        LOAD postgres;\n",
    "        ATTACH 'dbname={os.getenv(\"PGDATABASE\")} user={os.getenv(\"PGUSER\")} password={os.getenv(\"PGPASSWORD\")} \\\n",
    "            host={os.getenv(\"PGHOST\")} port={os.getenv(\"PGPORT\")}' AS remote_mimic (TYPE POSTGRES);\n",
    "    \"\"\")\n",
    "    print(\"DuckDB attached to remote PostgreSQL successfully.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error attaching PostgreSQL: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9ebd441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohort selection complete. Cohort size: 51,674 patients.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>stay_id</th>\n",
       "      <th>intime</th>\n",
       "      <th>outtime</th>\n",
       "      <th>age</th>\n",
       "      <th>y_ihm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000690</td>\n",
       "      <td>25860671</td>\n",
       "      <td>37081114</td>\n",
       "      <td>2150-11-02 19:37:00</td>\n",
       "      <td>2150-11-06 17:03:17</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001217</td>\n",
       "      <td>24597018</td>\n",
       "      <td>37067082</td>\n",
       "      <td>2157-11-20 19:18:02</td>\n",
       "      <td>2157-11-21 22:08:00</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10001725</td>\n",
       "      <td>25563031</td>\n",
       "      <td>31205490</td>\n",
       "      <td>2110-04-11 15:52:22</td>\n",
       "      <td>2110-04-12 23:59:56</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10001884</td>\n",
       "      <td>26184834</td>\n",
       "      <td>37510196</td>\n",
       "      <td>2131-01-11 04:20:05</td>\n",
       "      <td>2131-01-20 08:27:30</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10002013</td>\n",
       "      <td>23581541</td>\n",
       "      <td>39060235</td>\n",
       "      <td>2160-05-18 10:00:53</td>\n",
       "      <td>2160-05-19 17:33:33</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id   hadm_id   stay_id              intime             outtime  \\\n",
       "0    10000690  25860671  37081114 2150-11-02 19:37:00 2150-11-06 17:03:17   \n",
       "1    10001217  24597018  37067082 2157-11-20 19:18:02 2157-11-21 22:08:00   \n",
       "2    10001725  25563031  31205490 2110-04-11 15:52:22 2110-04-12 23:59:56   \n",
       "3    10001884  26184834  37510196 2131-01-11 04:20:05 2131-01-20 08:27:30   \n",
       "4    10002013  23581541  39060235 2160-05-18 10:00:53 2160-05-19 17:33:33   \n",
       "\n",
       "   age  y_ihm  \n",
       "0   86      0  \n",
       "1   55      0  \n",
       "2   46      0  \n",
       "3   77      1  \n",
       "4   57      0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "cohort_query = \"\"\"\n",
    "DROP TABLE IF EXISTS cohort_tab;\n",
    "CREATE TABLE cohort_tab AS\n",
    "WITH cohort AS (\n",
    "    SELECT\n",
    "        ic.subject_id,\n",
    "        ic.hadm_id,\n",
    "        ic.stay_id,\n",
    "        ic.intime,\n",
    "        ic.outtime,\n",
    "        -- Calculate age precisely using anchor_year logic\n",
    "        (pa.anchor_age + (date_part('year', ic.intime) - pa.anchor_year)) AS age,\n",
    "        adm.hospital_expire_flag,\n",
    "        adm.deathtime,\n",
    "        -- Rank stays: First stay of the first admission\n",
    "        ROW_NUMBER() OVER (PARTITION BY ic.subject_id ORDER BY ic.intime) AS stay_rank\n",
    "    FROM\n",
    "        remote_mimic.mimiciv_icu.icustays ic\n",
    "    INNER JOIN \n",
    "        remote_mimic.mimiciv_hosp.patients pa ON ic.subject_id = pa.subject_id\n",
    "    INNER JOIN \n",
    "        remote_mimic.mimiciv_hosp.admissions adm ON ic.hadm_id = adm.hadm_id\n",
    ")\n",
    "SELECT\n",
    "    subject_id,\n",
    "    hadm_id,\n",
    "    stay_id,\n",
    "    intime,\n",
    "    outtime,\n",
    "    age,\n",
    "    hospital_expire_flag AS y_ihm\n",
    "FROM\n",
    "    cohort\n",
    "WHERE\n",
    "    stay_rank = 1               -- First ICU stay only\n",
    "    AND age >= 18               -- Adults only\n",
    "    -- EXCLUSION: Patient must stay at least 24h to have a full observation window\n",
    "    AND date_diff('minute', intime, outtime) >= 1440 \n",
    "    -- EXCLUSION: If they died, they must have died AFTER the 24h window\n",
    "    -- (Prevents the model from 'seeing' the death process in the vitals)\n",
    "    AND (deathtime IS NULL OR deathtime > (intime + INTERVAL '24 HOURS'))\n",
    "ORDER BY\n",
    "    subject_id;\"\"\"\n",
    "\n",
    "con.sql(cohort_query)\n",
    "df_cohort = con.sql(\"SELECT * FROM cohort_tab\").df()\n",
    "print(f\"Cohort selection complete. Cohort size: {len(df_cohort):,} patients.\")\n",
    "df_cohort.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97d79b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hourly vitals extraction complete.\n",
      "Lab values extraction complete.\n",
      "Clinical scores extraction complete.\n"
     ]
    }
   ],
   "source": [
    "vitals_query = \"\"\"\n",
    "DROP TABLE IF EXISTS vitals_tab;\n",
    "CREATE TABLE vitals_tab AS (\n",
    "    SELECT \n",
    "        v.stay_id,\n",
    "        FLOOR(date_diff('second', c.intime, v.charttime) / 3600) AS hr,\n",
    "        v.heart_rate, v.sbp, v.spo2, v.temperature, v.resp_rate\n",
    "    FROM cohort_tab c\n",
    "    JOIN remote_mimic.mimiciv_derived.vitalsign v ON c.stay_id = v.stay_id\n",
    "    WHERE v.charttime BETWEEN c.intime AND (c.intime + INTERVAL '24 HOURS')\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "con.sql(vitals_query)\n",
    "print(\"Hourly vitals extraction complete.\")\n",
    "\n",
    "labs_query = \"\"\"\n",
    "DROP TABLE IF EXISTS labs_tab;\n",
    "CREATE TABLE labs_tab AS (\n",
    "    SELECT \n",
    "        fdl.stay_id,\n",
    "        fdb.lactate_max, fdl.bilirubin_total_max, fdl.creatinine_max, \n",
    "        fdl.wbc_max, fdl.glucose_max, fdl.bun_max\n",
    "    FROM remote_mimic.mimiciv_derived.first_day_lab fdl\n",
    "    JOIN remote_mimic.mimiciv_derived.first_day_bg_art fdb ON fdl.stay_id = fdb.stay_id\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "con.sql(labs_query)\n",
    "print(\"Lab values extraction complete.\")\n",
    "\n",
    "scores_query = \"\"\"\n",
    "DROP TABLE IF EXISTS scores_tab;\n",
    "CREATE TABLE scores_tab AS (\n",
    "    SELECT \n",
    "        s.stay_id, s.sapsii, o.oasis, so.sofa_24hours\n",
    "    FROM remote_mimic.mimiciv_derived.sapsii s\n",
    "    JOIN remote_mimic.mimiciv_derived.oasis o ON s.stay_id = o.stay_id\n",
    "    JOIN remote_mimic.mimiciv_derived.sofa so ON s.stay_id = so.stay_id\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "con.sql(scores_query)\n",
    "print(\"Clinical scores extraction complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf06abdc",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "features_query = \"\"\"\n",
    "DROP TABLE IF EXISTS features_tab;\n",
    "CREATE TABLE features_tab AS (\n",
    "    SELECT \n",
    "        v.*,\n",
    "        l.lactate_max, l.creatinine_max,\n",
    "        s.sapsii, s.sofa_24hours\n",
    "    FROM vitals_tab v\n",
    "    LEFT JOIN labs_tab l ON v.stay_id = l.stay_id\n",
    "    LEFT JOIN scores_tab s ON v.stay_id = s.stay_id\n",
    ");\"\"\"\n",
    "\n",
    "con.sql(features_query)\n",
    "df_features = con.sql(\"SELECT * FROM features_tab\").df()\n",
    "print(f\"Extracted {len(df_features):,} features for cohort.\")\n",
    "df_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5f87b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌────────────┬──────────┬──────────┬─────────┬────────────┬─────────────────────┬─────────────────────┬────────────────────┬────────────────────┬────────────────────────────────┬──────────────────────┬──────────────┬─────────────────┬─────────────────────┬─────────────────────┬─────────┬─────────────┬────────────────┐\n",
       "│ subject_id │ hadm_id  │ stay_id  │ gender  │    dod     │      admittime      │      dischtime      │    los_hospital    │   admission_age    │              race              │ hospital_expire_flag │ hospstay_seq │ first_hosp_stay │     icu_intime      │     icu_outtime     │ los_icu │ icustay_seq │ first_icu_stay │\n",
       "│   int32    │  int32   │  int32   │ varchar │    date    │      timestamp      │      timestamp      │       double       │       double       │            varchar             │        int16         │    int64     │     boolean     │      timestamp      │      timestamp      │ double  │    int64    │    boolean     │\n",
       "├────────────┼──────────┼──────────┼─────────┼────────────┼─────────────────────┼─────────────────────┼────────────────────┼────────────────────┼────────────────────────────────┼──────────────────────┼──────────────┼─────────────────┼─────────────────────┼─────────────────────┼─────────┼─────────────┼────────────────┤\n",
       "│   10000032 │ 29079034 │ 39553978 │ F       │ 2180-09-09 │ 2180-07-23 12:35:00 │ 2180-07-25 17:55:00 │ 2.2222222222222223 │  52.55996929585194 │ WHITE                          │                    0 │            1 │ true            │ 2180-07-23 14:00:00 │ 2180-07-23 23:50:47 │    0.41 │           1 │ true           │\n",
       "│   10000690 │ 25860671 │ 37081114 │ F       │ 2152-01-30 │ 2150-11-02 18:02:00 │ 2150-11-12 13:45:00 │  9.821527777777778 │  86.83712001601374 │ WHITE                          │                    0 │            1 │ true            │ 2150-11-02 19:37:00 │ 2150-11-06 17:03:17 │    3.89 │           1 │ true           │\n",
       "│   10000980 │ 26913865 │ 39765666 │ F       │ 2193-08-26 │ 2189-06-27 07:38:00 │ 2189-07-03 03:00:00 │ 5.8069444444444445 │  76.48623119891894 │ BLACK/AFRICAN AMERICAN         │                    0 │            1 │ true            │ 2189-06-27 08:42:00 │ 2189-06-27 20:38:27 │     0.5 │           1 │ true           │\n",
       "│   10001217 │ 24597018 │ 37067082 │ F       │ NULL       │ 2157-11-18 22:56:00 │ 2157-11-25 18:00:00 │  6.794444444444445 │   55.8814855782072 │ WHITE                          │                    0 │            1 │ true            │ 2157-11-20 19:18:02 │ 2157-11-21 22:08:00 │    1.12 │           1 │ true           │\n",
       "│   10001217 │ 27703517 │ 34592300 │ F       │ NULL       │ 2157-12-18 16:58:00 │ 2157-12-24 14:55:00 │  5.914583333333333 │   55.9629422258241 │ WHITE                          │                    0 │            2 │ false           │ 2157-12-19 15:42:24 │ 2157-12-20 14:27:41 │    0.95 │           1 │ true           │\n",
       "│   10001725 │ 25563031 │ 31205490 │ F       │ NULL       │ 2110-04-11 15:08:00 │ 2110-04-14 15:00:00 │ 2.9944444444444445 │ 46.275517480343325 │ WHITE                          │                    0 │            1 │ true            │ 2110-04-11 15:52:22 │ 2110-04-12 23:59:56 │    1.34 │           1 │ true           │\n",
       "│   10001843 │ 26133978 │ 39698942 │ M       │ 2134-12-06 │ 2134-12-05 00:10:00 │ 2134-12-06 12:54:00 │ 1.5305555555555557 │  76.92618303602664 │ WHITE                          │                    1 │            1 │ true            │ 2134-12-05 18:50:03 │ 2134-12-06 14:38:26 │    0.83 │           1 │ true           │\n",
       "│   10001884 │ 26184834 │ 37510196 │ F       │ 2131-01-20 │ 2131-01-07 20:39:00 │ 2131-01-20 05:15:00 │ 12.358333333333333 │  77.01829586046146 │ BLACK/AFRICAN AMERICAN         │                    1 │            1 │ true            │ 2131-01-11 04:20:05 │ 2131-01-20 08:27:30 │    9.17 │           1 │ true           │\n",
       "│   10002013 │ 23581541 │ 39060235 │ F       │ NULL       │ 2160-05-18 07:45:00 │ 2160-05-23 13:30:00 │  5.239583333333334 │  57.37880341435724 │ OTHER                          │                    0 │            1 │ true            │ 2160-05-18 10:00:53 │ 2160-05-19 17:33:33 │    1.31 │           1 │ true           │\n",
       "│   10002114 │ 27793700 │ 34672098 │ M       │ 2162-12-11 │ 2162-02-17 22:32:00 │ 2162-03-04 15:16:00 │ 14.697222222222221 │  56.13125239947457 │ UNKNOWN                        │                    0 │            1 │ true            │ 2162-02-17 23:30:00 │ 2162-02-20 21:16:27 │    2.91 │           1 │ true           │\n",
       "│       ·    │     ·    │     ·    │ ·       │  ·         │          ·          │          ·          │          ·         │          ·         │    ·                           │                    · │            · │  ·              │          ·          │          ·          │      ·  │           · │  ·             │\n",
       "│       ·    │     ·    │     ·    │ ·       │  ·         │          ·          │          ·          │          ·         │          ·         │    ·                           │                    · │            · │  ·              │          ·          │          ·          │      ·  │           · │  ·             │\n",
       "│       ·    │     ·    │     ·    │ ·       │  ·         │          ·          │          ·          │          ·         │          ·         │    ·                           │                    · │            · │  ·              │          ·          │          ·          │      ·  │           · │  ·             │\n",
       "│   15145917 │ 25244056 │ 30248885 │ M       │ NULL       │ 2110-06-14 20:22:00 │ 2110-06-30 14:34:00 │ 15.758333333333335 │  75.45134078531798 │ BLACK/AFRICAN AMERICAN         │                    0 │            1 │ true            │ 2110-06-14 20:38:25 │ 2110-06-15 11:56:24 │    0.64 │           1 │ true           │\n",
       "│   15145985 │ 29431463 │ 33246756 │ M       │ NULL       │ 2143-04-25 06:24:00 │ 2143-04-27 17:20:00 │ 2.4555555555555557 │  54.31285193561164 │ BLACK/AFRICAN AMERICAN         │                    0 │            1 │ true            │ 2143-04-25 08:21:00 │ 2143-04-26 19:02:50 │    1.45 │           1 │ true           │\n",
       "│   15146009 │ 25185450 │ 34562639 │ F       │ 2195-10-10 │ 2192-11-22 21:51:00 │ 2192-11-26 17:20:00 │  3.811805555555555 │  71.89456419761875 │ HISPANIC/LATINO - PUERTO RICAN │                    0 │            1 │ true            │ 2192-11-24 20:39:46 │ 2192-11-25 19:58:36 │    0.97 │           2 │ false          │\n",
       "│   15146009 │ 25185450 │ 30524356 │ F       │ 2195-10-10 │ 2192-11-22 21:51:00 │ 2192-11-26 17:20:00 │  3.811805555555555 │  71.89456419761875 │ HISPANIC/LATINO - PUERTO RICAN │                    0 │            1 │ true            │ 2192-11-22 22:47:00 │ 2192-11-24 17:24:05 │    1.78 │           1 │ true           │\n",
       "│   15146009 │ 26193445 │ 33596455 │ F       │ 2195-10-10 │ 2193-04-27 13:31:00 │ 2193-05-06 16:58:00 │            9.14375 │  72.32072761195165 │ HISPANIC/LATINO - PUERTO RICAN │                    0 │            2 │ false           │ 2193-04-27 14:26:00 │ 2193-04-29 13:07:32 │    1.95 │           1 │ true           │\n",
       "│   15146455 │ 20184452 │ 39938860 │ M       │ 2164-02-14 │ 2163-12-26 16:12:00 │ 2164-01-06 18:00:00 │             11.075 │  89.98435831585633 │ WHITE                          │                    0 │            1 │ true            │ 2163-12-29 22:37:40 │ 2164-01-06 18:15:36 │    7.82 │           1 │ true           │\n",
       "│   15146531 │ 24303509 │ 33971803 │ M       │ NULL       │ 2120-12-11 13:00:00 │ 2120-12-15 14:30:00 │             4.0625 │  71.94606224548838 │ WHITE                          │                    0 │            1 │ true            │ 2120-12-11 11:31:42 │ 2120-12-12 15:01:23 │    1.15 │           1 │ true           │\n",
       "│   15146593 │ 25872490 │ 38634844 │ M       │ NULL       │ 2183-02-09 00:00:00 │ 2183-02-14 17:12:00 │  5.716666666666667 │  61.10677851944738 │ OTHER                          │                    0 │            1 │ true            │ 2183-02-09 09:22:19 │ 2183-02-11 17:11:47 │    2.33 │           1 │ true           │\n",
       "│   15146626 │ 21016319 │ 34411482 │ M       │ NULL       │ 2118-09-06 13:44:00 │ 2118-09-21 14:25:00 │  15.02847222222222 │  43.68056856063164 │ UNKNOWN                        │                    0 │            1 │ true            │ 2118-09-06 15:45:00 │ 2118-09-09 21:23:22 │    3.23 │           1 │ true           │\n",
       "│   15146645 │ 28608616 │ 35089964 │ M       │ NULL       │ 2184-12-04 07:15:00 │ 2184-12-09 15:00:00 │  5.322916666666666 │  81.92624091241788 │ WHITE                          │                    0 │            1 │ true            │ 2184-12-05 09:40:15 │ 2184-12-07 12:07:13 │     2.1 │           1 │ true           │\n",
       "├────────────┴──────────┴──────────┴─────────┴────────────┴─────────────────────┴─────────────────────┴────────────────────┴────────────────────┴────────────────────────────────┴──────────────────────┴──────────────┴─────────────────┴─────────────────────┴─────────────────────┴─────────┴─────────────┴────────────────┤\n",
       "│ 50 rows (20 shown)                                                                                                                                                                                                                                                                                               18 columns │\n",
       "└─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# 1. Database Connection (Update with your credentials)\n",
    "# Format: 'postgresql://username:password@host:port/database'\n",
    "engine = create_engine('postgresql://user:pass@localhost:5432/mimiciv')\n",
    "\n",
    "def extract_mortality_features():\n",
    "    query = \"\"\"\n",
    "    SELECT \n",
    "        -- IDs and Labels\n",
    "        ie.subject_id, ie.hadm_id, ie.stay_id,\n",
    "        ie.hospital_expire_flag AS label,\n",
    "        \n",
    "        -- Demographics\n",
    "        ie.admission_age AS age,\n",
    "        CASE WHEN ie.gender = 'M' THEN 1 ELSE 0 END AS is_male,\n",
    "        \n",
    "        -- Derived Vitals (First 24h)\n",
    "        v.heart_rate_mean, v.mbp_mean, v.resp_rate_mean, v.spo2_mean, v.tempc_mean,\n",
    "        \n",
    "        -- Derived Labs (First 24h)\n",
    "        l.lactate_max, l.ph_min, l.bun_max, l.creatinine_max, l.glucose_max,\n",
    "        l.hemoglobin_min, l.wbc_max, l.aniongap_max,\n",
    "        \n",
    "        -- Severity & Comorbidity\n",
    "        c.charlson_comorbidity_index AS charlson_index,\n",
    "        aps.apsiii\n",
    "        \n",
    "    FROM mimic_derived.icustay_detail ie\n",
    "    LEFT JOIN mimic_derived.first_day_vitalsign v ON ie.stay_id = v.stay_id\n",
    "    LEFT JOIN mimic_derived.first_day_lab l ON ie.stay_id = l.stay_id\n",
    "    LEFT JOIN mimic_derived.charlson c ON ie.hadm_id = c.hadm_id\n",
    "    LEFT JOIN mimic_derived.apsiii aps ON ie.stay_id = aps.stay_id\n",
    "    \n",
    "    WHERE ie.admission_age >= 18  -- Only adults\n",
    "    AND ie.first_icu_stay = TRUE  -- Focus on first stay to avoid leakage\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Extracting features from mimic_derived...\")\n",
    "    df = pd.read_sql_query(query, engine)\n",
    "    \n",
    "    # Basic Preprocessing for Deep Learning\n",
    "    # 1. Handle missing values (simple median imputation for demonstration)\n",
    "    df = df.fillna(df.median())\n",
    "    \n",
    "    # 2. Normalize continuous features\n",
    "    cols_to_norm = ['age', 'heart_rate_mean', 'mbp_mean', 'resp_rate_mean', \n",
    "                    'spo2_mean', 'tempc_mean', 'lactate_max', 'ph_min', \n",
    "                    'bun_max', 'creatinine_max', 'glucose_max', 'aniongap_max',\n",
    "                    'charlson_index', 'apsiii']\n",
    "    \n",
    "    df[cols_to_norm] = (df[cols_to_norm] - df[cols_to_norm].mean()) / df[cols_to_norm].std()\n",
    "    \n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data = extract_mortality_features()\n",
    "    print(f\"Feature matrix shape: {data.shape}\")\n",
    "    print(data.head())\n",
    "    \n",
    "    # Save for training\n",
    "    # data.to_csv('mortality_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20660dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing high-performance join via DuckDB...\n",
      "Extracted 85242 rows.\n",
      "         subject_id       hadm_id       stay_id         label           age  \\\n",
      "count  8.524200e+04  8.524200e+04  8.524200e+04  85242.000000  85242.000000   \n",
      "mean   1.500086e+07  2.498190e+07  3.499439e+07      0.111154     65.224730   \n",
      "std    2.882597e+06  2.885086e+06  2.888970e+06      0.314325     16.871572   \n",
      "min    1.000003e+07  2.000009e+07  3.000015e+07      0.000000     18.002527   \n",
      "25%    1.251744e+07  2.248004e+07  3.249628e+07      0.000000     55.133382   \n",
      "50%    1.499738e+07  2.497768e+07  3.499647e+07      0.000000     66.919088   \n",
      "75%    1.751202e+07  2.746929e+07  3.748872e+07      0.000000     77.885681   \n",
      "max    1.999999e+07  2.999983e+07  3.999986e+07      1.000000    103.823298   \n",
      "\n",
      "            is_male  heart_rate_mean      mbp_mean  resp_rate_mean  \\\n",
      "count  85242.000000     85242.000000  85242.000000    85242.000000   \n",
      "mean       0.557566        84.424331     79.365232       19.111884   \n",
      "std        0.496678        15.922858     11.490355        3.806554   \n",
      "min        0.000000        28.500000     24.071429        6.000000   \n",
      "25%        0.000000        73.166667     71.428571       16.442308   \n",
      "50%        1.000000        82.875000     77.892857       18.486842   \n",
      "75%        1.000000        94.428571     86.137539       21.148148   \n",
      "max        1.000000       182.000000    159.470588       48.000000   \n",
      "\n",
      "       temperature_mean   lactate_max       bun_max  creatinine_max  \\\n",
      "count      85242.000000  85242.000000  85242.000000    85242.000000   \n",
      "mean          36.820691      2.513966     27.845792        1.570702   \n",
      "std            0.505524      1.792769     23.118888        1.792382   \n",
      "min           26.670000      0.000000      1.000000        0.100000   \n",
      "25%           36.604286      2.200000     14.000000        0.800000   \n",
      "50%           36.805000      2.200000     20.000000        1.000000   \n",
      "75%           37.039000      2.200000     33.000000        1.600000   \n",
      "max           41.110000     37.000000    279.000000       80.000000   \n",
      "\n",
      "       aniongap_max  charlson_index        apsiii  \n",
      "count  85242.000000    85242.000000  85242.000000  \n",
      "mean      16.034748        4.964208     42.676204  \n",
      "std        5.107719        3.035220     20.088669  \n",
      "min        2.000000        0.000000      0.000000  \n",
      "25%       13.000000        3.000000     29.000000  \n",
      "50%       15.000000        5.000000     39.000000  \n",
      "75%       18.000000        7.000000     52.000000  \n",
      "max       89.000000       20.000000    184.000000  \n"
     ]
    }
   ],
   "source": [
    "# SQL Query targeting the derived tables in the remote_mimic database\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    ie.subject_id, ie.hadm_id, ie.stay_id,\n",
    "    ie.hospital_expire_flag AS label,\n",
    "    ie.admission_age AS age,\n",
    "    CASE WHEN ie.gender = 'M' THEN 1 ELSE 0 END AS is_male,\n",
    "        \n",
    "    -- Aggregated Vitals\n",
    "    v.heart_rate_mean, v.mbp_mean, v.resp_rate_mean, v.temperature_mean,\n",
    "        \n",
    "    -- Critical Lab Markers\n",
    "    fdb.lactate_max, l.bun_max, l.creatinine_max, l.aniongap_max,\n",
    "        \n",
    "    -- Scoring Systems\n",
    "    c.charlson_comorbidity_index AS charlson_index,\n",
    "    aps.apsiii\n",
    "        \n",
    "FROM remote_mimic.mimiciv_derived.icustay_detail ie\n",
    "LEFT JOIN remote_mimic.mimiciv_derived.first_day_vitalsign v ON ie.stay_id = v.stay_id\n",
    "LEFT JOIN remote_mimic.mimiciv_derived.first_day_bg_art fdb ON ie.stay_id = fdb.stay_id\n",
    "LEFT JOIN remote_mimic.mimiciv_derived.first_day_lab l ON ie.stay_id = l.stay_id\n",
    "LEFT JOIN remote_mimic.mimiciv_derived.charlson c ON ie.hadm_id = c.hadm_id\n",
    "LEFT JOIN remote_mimic.mimiciv_derived.apsiii aps ON ie.stay_id = aps.stay_id\n",
    "    \n",
    "WHERE ie.admission_age >= 18 \n",
    "AND ie.first_icu_stay = TRUE\n",
    "\"\"\"\n",
    "    \n",
    "print(\"Executing high-performance join via DuckDB...\")\n",
    "# DuckDB returns a Relation object, .df() converts it to a Pandas DataFrame\n",
    "df = con.execute(query).df()\n",
    "    \n",
    "# Pre-processing for Deep Learning - handling nulls (common in clinical data)\n",
    "df = df.fillna(df.median(numeric_only=True))\n",
    "\n",
    "print(f\"Extracted {len(df)} rows.\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48969ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (68193, 12)\n",
      "Testing set size: (17049, 12)\n",
      "\n",
      "Scaled Training Means (should be ~0):\n",
      "age                 0.0\n",
      "is_male             0.0\n",
      "heart_rate_mean    -0.0\n",
      "mbp_mean           -0.0\n",
      "resp_rate_mean     -0.0\n",
      "temperature_mean    0.0\n",
      "lactate_max         0.0\n",
      "bun_max             0.0\n",
      "creatinine_max      0.0\n",
      "aniongap_max       -0.0\n",
      "charlson_index      0.0\n",
      "apsiii              0.0\n",
      "dtype: float64\n",
      "\n",
      "Extraction Complete.\n",
      "Features for Training: ['age', 'is_male', 'heart_rate_mean', 'mbp_mean', 'resp_rate_mean', 'temperature_mean', 'lactate_max', 'bun_max', 'creatinine_max', 'aniongap_max', 'charlson_index', 'apsiii']\n",
      "Sample Scaled Row (Binary Gender included):\n",
      "age                -0.483959\n",
      "is_male            -1.123328\n",
      "heart_rate_mean    -0.348504\n",
      "mbp_mean           -0.067863\n",
      "resp_rate_mean     -0.826689\n",
      "temperature_mean    0.196113\n",
      "lactate_max        -0.174633\n",
      "bun_max            -0.470604\n",
      "creatinine_max     -0.540344\n",
      "aniongap_max        0.578217\n",
      "charlson_index     -0.648463\n",
      "apsiii             -0.682433\n",
      "Name: 56652, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def extract_and_preprocess_mimic():\n",
    "    global df  # Use the DataFrame extracted above\n",
    "    \n",
    "    # 2. Identify Features and Target\n",
    "    # We drop 'stay_id' as it's an identifier, and 'label' is our target\n",
    "    X = df.drop(columns=['subject_id', 'hadm_id', 'stay_id', 'label'])\n",
    "    y = df['label']\n",
    "\n",
    "    # 3. Train-Test Split (Crucial for Deep Learning)\n",
    "    # We split BEFORE scaling to prevent data leakage\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "        )\n",
    "    # 4. Use Scikit-Learn StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Define numeric columns that need scaling (age, vitals, labs, scores)\n",
    "    # Binary/Categorical columns like 'is_male' don't strictly require Z-score scaling, \n",
    "    # but for Neural Nets, it's often safer to scale everything.\n",
    "    cols_to_scale = X_train.columns \n",
    "\n",
    "    # fit_transform on Training data: Calculates Mean and Std\n",
    "    X_train_scaled = X_train.copy()\n",
    "    X_train_scaled[cols_to_scale] = scaler.fit_transform(X_train[cols_to_scale])\n",
    "\n",
    "    # transform on Test data: Uses the Mean and Std from Training (no new calculation)\n",
    "    X_test_scaled = X_test.copy()\n",
    "    X_test_scaled[cols_to_scale] = scaler.transform(X_test[cols_to_scale])\n",
    "\n",
    "    return X_train_scaled, X_test_scaled, y_train, y_test, scaler\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    X_train, X_test, y_train, y_test, fitted_scaler = extract_and_preprocess_mimic()\n",
    "    \n",
    "    print(f\"Training set size: {X_train.shape}\")\n",
    "    print(f\"Testing set size: {X_test.shape}\")\n",
    "    print(\"\\nScaled Training Means (should be ~0):\")\n",
    "    print(X_train.mean().round(2))\n",
    "    print(\"\\nExtraction Complete.\")\n",
    "    print(f\"Features for Training: {list(X_train.columns)}\")\n",
    "    print(f\"Sample Scaled Row (Binary Gender included):\\n{X_train.iloc[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6f53db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.13/site-packages/keras/src/export/tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "\n",
    "def build_and_train_model(X_train, X_test, y_train, y_test):\n",
    "    # 1. Define the Architecture\n",
    "    # We use a simple 3-layer dense network with Dropout to prevent overfitting\n",
    "    model = models.Sequential([\n",
    "        # Input layer size matches the number of features (e.g., 12)\n",
    "        layers.Input(shape=(X_train.shape[1],)),\n",
    "        \n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dropout(0.2),  # Randomly shuts off 20% of neurons to improve generalization\n",
    "        \n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dropout(0.1),\n",
    "        \n",
    "        layers.Dense(16, activation='relu'),\n",
    "        \n",
    "        # Output layer: Sigmoid is used for binary classification (probability 0-1)\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    # 2. Compile the Model\n",
    "    # Binary Crossentropy is the standard loss function for mortality (0/1) prediction\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
    "    )\n",
    "\n",
    "    # 3. Early Stopping\n",
    "    # This stops training when the model stops improving on the test set\n",
    "    early_stop = callbacks.EarlyStopping(\n",
    "        monitor='val_loss', \n",
    "        patience=5, \n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    # 4. Train\n",
    "    print(\"Starting training...\")\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_test, y_test),\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        callbacks=[early_stop],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    return model, history\n",
    "\n",
    "# Usage assuming X_train etc. were generated by the previous DuckDB/Scikit script\n",
    "# model, history = build_and_train_model(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785c5130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 1 Complete. Cohort size: 64,363 patients.\n"
     ]
    }
   ],
   "source": [
    "cohort_sql = \"\"\"\n",
    "WITH FirstICUStay AS (\n",
    "    -- Select the minimum ICUSTAY_ID for each SUBJECT_ID to enforce 'First ICU Stay'\n",
    "    SELECT\n",
    "        ic.subject_id,\n",
    "        ic.hadm_id,\n",
    "        ic.stay_id,\n",
    "        ic.intime,\n",
    "        ic.outtime,\n",
    "        ic.los,\n",
    "        ROW_NUMBER() OVER (PARTITION BY ic.subject_id ORDER BY ic.intime) AS rn\n",
    "    FROM\n",
    "        remote_mimic.mimiciv_icu.icustays ic\n",
    "),\n",
    "AdultPatients AS (\n",
    "    -- Calculate age and filter for adult patients\n",
    "    SELECT\n",
    "        fs.*,\n",
    "        pa.gender,\n",
    "        (\n",
    "            (CAST(STRFTIME(fs.intime, '%Y') AS INTEGER) - pa.anchor_year) + pa.anchor_age\n",
    "        ) AS age_at_admission\n",
    "    FROM\n",
    "        FirstICUStay fs\n",
    "    INNER JOIN \n",
    "        remote_mimic.mimiciv_hosp.patients pa ON fs.subject_id = pa.subject_id\n",
    "    WHERE\n",
    "        fs.rn = 1 -- Only the first ICU stay\n",
    ")\n",
    "SELECT\n",
    "    ap.subject_id,\n",
    "    ap.hadm_id,\n",
    "    ap.stay_id,\n",
    "    ap.intime,\n",
    "    ap.outtime,\n",
    "    ap.los,\n",
    "    ap.gender,\n",
    "    ap.age_at_admission AS age,\n",
    "    -- Target Label: In-Hospital Mortality (IHM)\n",
    "    adm.hospital_expire_flag AS y_ihm\n",
    "FROM\n",
    "    AdultPatients ap\n",
    "INNER JOIN \n",
    "    remote_mimic.mimiciv_hosp.admissions adm ON ap.hadm_id = adm.hadm_id\n",
    "WHERE\n",
    "    ap.age_at_admission >= 18 -- Inclusion: Adult patients\n",
    "AND ap.los * 24 >= 8 -- Exclusion: Minimum length of stay\n",
    "ORDER BY\n",
    "    ap.subject_id, ap.intime;\n",
    "\"\"\"\n",
    "\n",
    "# Execute and store the core cohort data\n",
    "df_cohort = con.sql(cohort_sql).df()\n",
    "print(f\"Phase 1 Complete. Cohort size: {len(df_cohort):,} patients.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0af1b6c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 64,363 static, derived feature vectors.\n"
     ]
    }
   ],
   "source": [
    "static_feat_sql = \"\"\"\n",
    "SELECT\n",
    "    coh.stay_id,\n",
    "    coh.subject_id,\n",
    "    coh.age,\n",
    "    coh.gender,\n",
    "    coh.y_ihm,\n",
    "    -- Comorbidities\n",
    "    cci.charlson_comorbidity_index,\n",
    "    -- Severity Scores (First 24 Hours - Static)\n",
    "    o.oasis,\n",
    "    saps.sapsii,\n",
    "    -- First Day Vitals (min/max/mean)\n",
    "    g.gcs_min, -- Example GCS feature\n",
    "    fvl.heart_rate_min, -- Min Heart Rate in first 24h\n",
    "    fvl.sbp_max,        -- Max Systolic BP in first 24h\n",
    "    fvl.resp_rate_mean  -- Mean Respiratory Rate in first 24h\n",
    "FROM\n",
    "    df_cohort coh\n",
    "LEFT JOIN\n",
    "    remote_mimic.mimiciv_derived.charlson cci ON coh.hadm_id = cci.hadm_id\n",
    "LEFT JOIN\n",
    "    remote_mimic.mimiciv_derived.oasis o ON coh.stay_id = o.stay_id\n",
    "LEFT JOIN\n",
    "    remote_mimic.mimiciv_derived.sapsii saps ON coh.stay_id = saps.stay_id\n",
    "LEFT JOIN\n",
    "    remote_mimic.mimiciv_derived.first_day_gcs g ON coh.stay_id = g.stay_id\n",
    "LEFT JOIN\n",
    "    remote_mimic.mimiciv_derived.first_day_vitalsign fvl ON coh.stay_id = fvl.stay_id\n",
    "LEFT JOIN\n",
    "    remote_mimic.mimiciv_derived.first_day_lab fdl ON coh.stay_id = fdl.stay_id;\n",
    "\"\"\"\n",
    "\n",
    "df_static_feat = con.sql(static_feat_sql).df()\n",
    "print(f\"Extracted {len(df_static_feat):,} static, derived feature vectors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae0199d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 1,475,981 dynamic SOFA score entries.\n"
     ]
    }
   ],
   "source": [
    "sofa_sql = \"\"\"\n",
    "SELECT\n",
    "    s.stay_id,\n",
    "    -- Time from ICU intime in hours (already calculated in the derived table)\n",
    "    s.starttime,\n",
    "    s.sofa_24hours, -- The total score for the 24 hour period\n",
    "    s.respiration,\n",
    "    s.coagulation,\n",
    "    s.liver,\n",
    "    s.cardiovascular,\n",
    "    s.cns,\n",
    "    s.renal\n",
    "FROM\n",
    "    remote_mimic.mimiciv_derived.sofa s\n",
    "INNER JOIN\n",
    "    df_cohort coh ON s.stay_id = coh.stay_id\n",
    "-- Filter to ensure we only get scores calculated during the observation window\n",
    "WHERE\n",
    "    s.starttime < coh.intime + INTERVAL '24 hour'\n",
    "ORDER BY\n",
    "    s.stay_id, s.starttime;\n",
    "\"\"\"\n",
    "\n",
    "df_sofa = con.sql(sofa_sql).df()\n",
    "print(f\"Extracted {len(df_sofa):,} dynamic SOFA score entries.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
