{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0700f321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DuckDB attached to remote PostgreSQL successfully.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>label</th>\n",
       "      <th>anchor_age</th>\n",
       "      <th>gender</th>\n",
       "      <th>stay_id</th>\n",
       "      <th>icu_intime</th>\n",
       "      <th>charlson_comorbidity_index</th>\n",
       "      <th>heart_rate_mean</th>\n",
       "      <th>sbp_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>hematocrit</th>\n",
       "      <th>hemoglobin</th>\n",
       "      <th>wbc</th>\n",
       "      <th>platelet</th>\n",
       "      <th>creatinine</th>\n",
       "      <th>bun</th>\n",
       "      <th>pf_ratio</th>\n",
       "      <th>ck_mb</th>\n",
       "      <th>prev_mi</th>\n",
       "      <th>stroke_history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13467195</td>\n",
       "      <td>21154580</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>M</td>\n",
       "      <td>34490721</td>\n",
       "      <td>2181-05-14 08:48:07</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>43.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>5.9</td>\n",
       "      <td>225.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13468386</td>\n",
       "      <td>24561318</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>M</td>\n",
       "      <td>34950661</td>\n",
       "      <td>2174-06-24 10:48:52</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>48.8</td>\n",
       "      <td>16.9</td>\n",
       "      <td>10.4</td>\n",
       "      <td>201.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13468386</td>\n",
       "      <td>24561318</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>M</td>\n",
       "      <td>34950661</td>\n",
       "      <td>2174-06-24 10:48:52</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>48.8</td>\n",
       "      <td>16.9</td>\n",
       "      <td>10.4</td>\n",
       "      <td>201.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13466375</td>\n",
       "      <td>21011631</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>M</td>\n",
       "      <td>36305045</td>\n",
       "      <td>2149-09-19 12:19:26</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>44.7</td>\n",
       "      <td>14.7</td>\n",
       "      <td>26.2</td>\n",
       "      <td>341.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>74.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13466461</td>\n",
       "      <td>24748943</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>F</td>\n",
       "      <td>33383412</td>\n",
       "      <td>2136-01-16 09:25:50</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>31.7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.6</td>\n",
       "      <td>192.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id   hadm_id  label  anchor_age gender   stay_id  \\\n",
       "0    13467195  21154580      0          68      M  34490721   \n",
       "1    13468386  24561318      0          63      M  34950661   \n",
       "2    13468386  24561318      0          63      M  34950661   \n",
       "3    13466375  21011631      0          70      M  36305045   \n",
       "4    13466461  24748943      0          88      F  33383412   \n",
       "\n",
       "           icu_intime  charlson_comorbidity_index  heart_rate_mean  sbp_mean  \\\n",
       "0 2181-05-14 08:48:07                           2              NaN       NaN   \n",
       "1 2174-06-24 10:48:52                           5              NaN       NaN   \n",
       "2 2174-06-24 10:48:52                           5              NaN       NaN   \n",
       "3 2149-09-19 12:19:26                           6              NaN       NaN   \n",
       "4 2136-01-16 09:25:50                          10              NaN       NaN   \n",
       "\n",
       "   ...  hematocrit  hemoglobin   wbc  platelet  creatinine   bun  pf_ratio  \\\n",
       "0  ...        43.0        15.5   5.9     225.0         1.1  14.0       NaN   \n",
       "1  ...        48.8        16.9  10.4     201.0         1.0  23.0       NaN   \n",
       "2  ...        48.8        16.9  10.4     201.0         1.0  23.0       NaN   \n",
       "3  ...        44.7        14.7  26.2     341.0         2.3  74.0       NaN   \n",
       "4  ...        31.7        10.0   9.6     192.0         1.7  42.0       NaN   \n",
       "\n",
       "   ck_mb  prev_mi  stroke_history  \n",
       "0    NaN        0               0  \n",
       "1    NaN        1               0  \n",
       "2    NaN        1               0  \n",
       "3    NaN        0               0  \n",
       "4   22.0        1               0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from db import attach_duckdb, duckdb_to_df, load_sql\n",
    "\n",
    "attach_duckdb(\"remote_mimic\")\n",
    "query = load_sql(\"rev-cohort.sql\")\n",
    "df = duckdb_to_df(query)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab1e848",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# --- Step A: Define Feature Groups ---\n",
    "# Continuous features need scaling + median imputation\n",
    "continuous_cols = ['anchor_age', 'heart_rate_mean', 'sbp_mean', 'dbp_mean', 'mbp_mean', 'resp_rate_mean',\n",
    "                   'spo2_mean', 'hematocrit', 'hemoglobin', 'wbc', 'platelet', 'creatinine',\n",
    "                   'bun', 'pf_ratio', 'ck_mb']\n",
    "# Score/Binary features need 0 imputation\n",
    "score_cols = ['charlson_comorbidity_index', 'prev_mi', 'stroke_history']\n",
    "\n",
    "# --- Step B: Handle Missing Values (The \"Dual Strategy\") ---\n",
    "# 1. Impute Continuous with MEDIAN\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "df[continuous_cols] = imputer.fit_transform(df[continuous_cols])\n",
    "\n",
    "# 2. Impute Scores with ZERO (Assume NULL = Absence of condition)\n",
    "df[score_cols] = df[score_cols].fillna(0)\n",
    "\n",
    "# --- Step C: Encoding ---\n",
    "le = LabelEncoder()\n",
    "df['gender'] = le.fit_transform(df['gender'])\n",
    "\n",
    "# Combine all features\n",
    "feature_cols = continuous_cols + score_cols + ['gender']\n",
    "X = df[feature_cols].values\n",
    "y = df['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b55279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step D: Stratified Splitting ---\n",
    "# Stratify=y ensures we have the same % of mortality in Train, Val, and Test\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n",
    "\n",
    "# --- Step E: Scaling (Standardization) ---\n",
    "# CRITICAL: Fit scaler ONLY on X_train to prevent info leakage from Test set\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# ==========================================\n",
    "# 3. Addressing Class Imbalance\n",
    "# ==========================================\n",
    "# Calculate positive weight for BCEWithLogitsLoss\n",
    "# Formula: number_of_negatives / number_of_positives\n",
    "num_neg = (y_train == 0).sum()\n",
    "num_pos = (y_train == 1).sum()\n",
    "pos_weight_value = num_neg / num_pos\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(f\"Train Shape: {X_train.shape}\")\n",
    "print(f\"Class Balance (Train): {num_neg} Survivors vs {num_pos} Deaths\")\n",
    "print(f\"Calculated pos_weight: {pos_weight_value:.4f}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# ==========================================\n",
    "# 4. Prepare for PyTorch\n",
    "# ==========================================\n",
    "# Convert to Tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train)\n",
    "y_train_tensor = torch.FloatTensor(y_train).unsqueeze(1)\n",
    "pos_weight_tensor = torch.FloatTensor([pos_weight_value])\n",
    "\n",
    "print(\"Ready for Model Training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806fc8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# 1. Convert to PyTorch Tensors\n",
    "train_data = TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train).unsqueeze(1))\n",
    "val_data = TensorDataset(torch.FloatTensor(X_val), torch.FloatTensor(y_val).unsqueeze(1))\n",
    "test_data = TensorDataset(torch.FloatTensor(X_test), torch.FloatTensor(y_test).unsqueeze(1))\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=64)\n",
    "\n",
    "# 2. Define the Architecture\n",
    "class MortalityPredictor(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(MortalityPredictor, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),  # Prevent overfitting\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid()      # Output probability between 0 and 1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "# 3. Training Setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MortalityPredictor(input_dim=X_train.shape[1]).to(device)\n",
    "#criterion = nn.BCELoss() # Binary Cross Entropy for classification\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight_tensor)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 4. Training Loop\n",
    "epochs = 20\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10270dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc\n",
    "\n",
    "model.eval()\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader: # Use val or test loader\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs)\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(outputs.cpu().numpy())\n",
    "\n",
    "roc_auc = roc_auc_score(y_true, y_pred)\n",
    "print(f\"Model AUC-ROC: {roc_auc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
